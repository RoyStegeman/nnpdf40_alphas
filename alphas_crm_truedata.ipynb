{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c3594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from validphys.loader import FallbackLoader as Loader\n",
    "from validphys.api import API\n",
    "from collections import defaultdict\n",
    "from scipy.stats import norm\n",
    "from validphys.plotutils import kde_plot\n",
    "from nnpdf_data import legacy_to_new_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1db218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_names = [f\"241123-rs-n3lo_3pt_qed-alphas_0{n}\" for n in range(114,126)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb1ad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Loader()\n",
    "fits = [l.check_fit(f) for f in fit_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ac6692",
   "metadata": {},
   "source": [
    "# Correlated Replica Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32685b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "as_fits = defaultdict(list)\n",
    "for f in fits:\n",
    "    th = f.as_input()[\"theory\"][\"theoryid\"]\n",
    "    alpha = API.theory_info_table(theory_db_id = th).loc[\"alphas\"].iloc[0]\n",
    "    as_fits[alpha].append(f)\n",
    "as_fits = dict(as_fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd0980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = {f: API.fitted_replica_indexes(pdf=f.name) for f in fits}\n",
    "replica_data = {f: API.replica_data(fit=f.name) for f in fits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1644bac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(replica_data):\n",
    "    return replica_data.training*3439 + replica_data.validation*1177\n",
    "    # return replica_data.chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375353b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_values = {}\n",
    "for alpha, flist in as_fits.items():\n",
    "    series = []\n",
    "    for f in flist:\n",
    "        s = [measure(d) for d in replica_data[f]]\n",
    "        series.append(pd.Series(s, index=indexes[f]))\n",
    "    min_values[alpha] = pd.DataFrame(series).min()\n",
    "data = pd.DataFrame(min_values).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec6db68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quadratic polynomial\n",
    "mins = {}\n",
    "filter_this_row = [] # rows that are filtered\n",
    "invcov = np.linalg.inv(np.cov(data.T))\n",
    "for ind, row in data.iterrows():\n",
    "    p2, p1, p0 = np.polyfit(data.columns, row, 2)\n",
    "    if not np.isnan(p1): # NaN if not all replicas passed postfit\n",
    "\n",
    "        # Calculate difference between fitted parabola and datapoint\n",
    "        y_fit = p2 * data.columns**2 + p1 * data.columns + p0\n",
    "        diff = (row - y_fit)@invcov@(row - y_fit)\n",
    "        # if data is non-parabolic, neglect the replica\n",
    "        # if diff > 10 or p2 < 3500:\n",
    "        #     filter_this_row.append(ind)\n",
    "        #     continue\n",
    "\n",
    "        mins[ind] = -p1 / 2 / p2\n",
    "mins = pd.Series(mins)\n",
    "mins_quadratic = pd.Series(mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9d53c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the bootstrap\n",
    "n_bootstrap = 1000  # Number of bootstrap samples\n",
    "ci_percentile = 0.68  # 68% confidence interval\n",
    "\n",
    "# Function to compute the confidence interval\n",
    "def compute_ci(series, percentile):\n",
    "    lower_bound = np.percentile(series, (1 - percentile) / 2 * 100)\n",
    "    upper_bound = np.percentile(series, (1 + percentile) / 2 * 100)\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "bootstrap_cis = []\n",
    "for _ in range(n_bootstrap):\n",
    "    # Resample with replacement\n",
    "    sample = np.random.choice(mins, size=len(mins), replace=True)\n",
    "    # Compute confidence interval for the sample\n",
    "    ci = compute_ci(sample, ci_percentile)\n",
    "    bootstrap_cis.append(ci)\n",
    "\n",
    "# Convert to a DataFrame for easier analysis\n",
    "bootstrap_cis_df = pd.DataFrame(bootstrap_cis, columns=['lower', 'upper'])\n",
    "\n",
    "# Calculate the bootstrap error (standard deviation of the CIs)\n",
    "ci_error = bootstrap_cis_df.std()\n",
    "\n",
    "np.std([j-i for i,j in bootstrap_cis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7909e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mins.describe(percentiles=[0.16,0.84]))\n",
    "print(\"\")\n",
    "print(f\"cv±std = {mins.mean():.4f} ± {mins.std():.4f} \")\n",
    "print(f\"1std interval:  {mins.mean()-mins.std():.5f} to {mins.mean()+mins.std():.5f} \")\n",
    "print(f\"68% c.i:        {mins.describe(percentiles=[0.16,0.84])[4]:.5f} to {mins.describe(percentiles=[0.16,0.84])[6]:.5f} \")\n",
    "print(f\"68% c.i:        {(mins.describe(percentiles=[0.16,0.84])[4] + mins.describe(percentiles=[0.16,0.84])[6])/2:.4f} ± {(mins.describe(percentiles=[0.16,0.84])[6] - mins.describe(percentiles=[0.16,0.84])[4])/2:.4f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6c37c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "kde_plot(mins,ax=ax)\n",
    "central = (mins.describe(percentiles=[0.16,0.84])[6] + mins.describe(percentiles=[0.16,0.84])[4])/2\n",
    "unc = (mins.describe(percentiles=[0.16,0.84])[6] - mins.describe(percentiles=[0.16,0.84])[4])/2\n",
    "ax.set_title(f\"68% c.i: {central:.4f}  ± {unc:.4f}\")\n",
    "# ax.set_xlim(0.118,0.13)\n",
    "ax.set_xlabel(r\"$\\alpha_s(M_Z)$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6433e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mins,bins=data.columns-0.0005,edgecolor='black',density=True)\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "# p = np.exp(-((x-mins.mean())/mins.std())**2/2)*mins.size/np.sqrt(2*np.pi)\n",
    "p = norm.pdf(x, mins.mean(), mins.std())\n",
    "plt.plot(x,p,'k',label=f\"{mins.mean():.5f} +/- {mins.std():.5f}\")\n",
    "plt.yticks([])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ed58fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data.columns, data.T/4616, color='blue', lw=0.2)\n",
    "plt.ylabel(r\"$\\chi^2$\")\n",
    "plt.xlabel(r\"$\\alpha_s(M_Z)$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a5fa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "norm = Normalize(vmin=mins.min(), vmax=mins.max())\n",
    "\n",
    "# Choose the yellow-to-green colormap\n",
    "colormap = cm.YlGn\n",
    "\n",
    "# Plot each row of the transposed DataFrame and color them based on 'mins' values\n",
    "for i, row in enumerate(np.array(data)):\n",
    "    plt.plot(data.columns, row, color=colormap(norm(mins.iloc[i])))\n",
    "\n",
    "# Add a colorbar to indicate the mapping from 'mins' values to the color gradient\n",
    "sm = plt.cm.ScalarMappable(cmap=colormap, norm=norm)\n",
    "sm.set_array([])\n",
    "plt.colorbar(sm, label=\"Mins Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d6817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fitn in fit_names:\n",
    "    print(API.fit(fit=fitn).as_input()[\"theory\"][\"theoryid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b9adf8",
   "metadata": {},
   "source": [
    "# Experimental/naive method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7eb462",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_dict = dict(\n",
    "    fit=fit_names[0],\n",
    "    dataset_inputs={\"from_\": \"fit\"},\n",
    "    pdf={\"from_\": \"fit\"},\n",
    "    use_cuts=\"fromfit\",\n",
    "    theory={\"from_\": \"fit\"},\n",
    "    theoryid={\"from_\": \"theory\"},\n",
    ")\n",
    "\n",
    "# Experimental covariance matrix\n",
    "# C = API.groups_covmat(\n",
    "#     use_t0 = False,\n",
    "#     **naive_dict\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# t0 covariance matrix (the correct one, see bottom of page 15 of https://arxiv.org/pdf/1802.03398)\n",
    "C = API.groups_covmat(\n",
    "    fit=fit_names[0],\n",
    "    use_t0 = True,\n",
    "    use_cuts=\"fromfit\",\n",
    "    datacuts={\"from_\": \"fit\"},\n",
    "    t0pdfset={\"from_\": \"datacuts\"},\n",
    "    dataset_inputs={\"from_\": \"fit\"},\n",
    "    theoryid=API.fit(fit=fit_names[0]).as_input()[\"theory\"][\"t0theoryid\"],\n",
    ")\n",
    "\n",
    "# the datapoint is already uniquely defined by the dataset and datapoint, we dont need the process\n",
    "C = C.droplevel(0, axis=0).droplevel(0, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aa1538",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    stored_covmat = pd.read_csv(\n",
    "        fits[0].path / \"tables/datacuts_theory_theorycovmatconfig_theory_covmat_custom.csv\",\n",
    "        index_col=[0, 1, 2],\n",
    "        header=[0, 1, 2],\n",
    "        sep=\"\\t|,\",\n",
    "        engine=\"python\",\n",
    "    ).fillna(0)\n",
    "    tmp = stored_covmat.droplevel(0, axis=0).droplevel(0, axis=1) # drop process level\n",
    "    new_names = {d[0]: legacy_to_new_map(d[0])[0] for d in tmp.index}\n",
    "    tmp.rename(columns=new_names, index=new_names, level=0, inplace=True) # rename datasets using the legacy to new map\n",
    "    tmp_index = pd.MultiIndex.from_tuples(\n",
    "        [(bb, np.int64(cc)) for bb, cc in tmp.index],\n",
    "        names=[\"dataset\", \"id\"],\n",
    "    ) # make sure the index is an int, just as it is in C\n",
    "    tmp = pd.DataFrame(\n",
    "        tmp.values, index=tmp_index, columns=tmp_index\n",
    "    )\n",
    "    stored_covmat = tmp.reindex(C.index).T.reindex(C.index)\n",
    "    if stored_covmat.isnull().values.any():\n",
    "        print(\"some values are NaN, meaning that not all indices in C.index exist in tmp\")\n",
    "    invcov = np.linalg.inv(C+stored_covmat)\n",
    "except:\n",
    "    invcov = np.linalg.inv(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79943dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_values = []\n",
    "alphas_values = []\n",
    "for fitname in fit_names:\n",
    "    naive_dict[\"fit\"] = fitname\n",
    "    central_preds_and_data = API.group_result_central_table_no_table(**naive_dict)\n",
    "\n",
    "    theory_db_id = API.fit(fit=fitname).as_input()[\"theory\"][\"theoryid\"]\n",
    "    alphas_values.append(API.theory_info_table(theory_db_id = theory_db_id).loc[\"alphas\"].iloc[0])\n",
    "\n",
    "    # compute chi2\n",
    "    diff = central_preds_and_data.theory_central - central_preds_and_data.data_central\n",
    "    chi2_values.append(diff @ invcov @ diff / diff.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acfcb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = np.polyfit(alphas_values, chi2_values, 2)\n",
    "\n",
    "central = -b / 2 / a\n",
    "ndata = C.shape[0]\n",
    "unc = np.sqrt(1/a/ndata)\n",
    "\n",
    "plt.scatter(alphas_values, chi2_values, color=\"blue\" )\n",
    "xgrid = np.linspace(min(alphas_values),max(alphas_values))\n",
    "plt.plot(xgrid, [a*x*x + b*x + c for x in xgrid], color=\"black\", linestyle=\"--\")\n",
    "plt.title(rf\"$\\alpha_s$={central:.4f}$\\pm${unc:.4f}\")\n",
    "print(f\"{central:.4f} ± {unc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnpdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "589e3134e9d89160e5ace28972e8dc0b682f48816407b59cbfdad217f6fb745b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
