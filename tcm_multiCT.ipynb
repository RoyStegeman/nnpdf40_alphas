{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48a3ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = [99843, 92935, 91761, 91361, 89580, 88921, 86725, 81843, 78995, 71347, 7023, 68128, 66694, 64348, 61880, 56857, 5403, 44830, 38229, 36240, 35205, 3345348918, 20168, 12919, 10290]\n",
    "covmat_scaling_factor = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6d995d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from validphys.api import API\n",
    "from validphys.loader import FallbackLoader\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "l = FallbackLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adaa6496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHAPDF 6.4.0 loading all 101 PDFs in set 240411-ab-ct-alphas118-nlo\n",
      "240411-ab-ct-alphas118-nlo, version 1; 101 PDF members\n"
     ]
    }
   ],
   "source": [
    "#fitnames = [f\"240715-ab-multict-fseed{seed}-tcm-nlo\" for seed in seed_list]\n",
    "fitnames = [f\"240715-ab-multict-fseed{seed}-tcm-nlo\" for seed in [10290, 3345348918]]\n",
    "fits = [API.fit(fit=fitname) for fitname in fitnames]\n",
    "\n",
    "# always the same so just take the first\n",
    "prior_pdf = fits[0].as_input()[\"theorycovmatconfig\"][\"pdf\"]\n",
    "\n",
    "common_dicts = [dict(\n",
    "    dataset_inputs={\"from_\": \"fit\"},\n",
    "    fit=fit.name,\n",
    "    fits=[fit.name],\n",
    "    use_cuts=\"fromfit\",\n",
    "    metadata_group=\"nnpdf31_process\",\n",
    ") for fit in fits]\n",
    "\n",
    "theoryids_dicts = [({\n",
    "        \"point_prescription\": {\"from_\": \"theorycovmatconfig\"},\n",
    "        \"theoryids\":{ \"from_\": \"scale_variation_theories\"},\n",
    "        \"t0theoryid\": {\"from_\": \"theory\"},\n",
    "        \"theoryid\": {\"from_\": \"theory\"},\n",
    "        \"theory\": {\"from_\": \"fit\"},\n",
    "        \"theorycovmatconfig\": {\"from_\": \"fit\"},\n",
    "    } | common_dict) for common_dict in common_dicts]\n",
    "\n",
    "# they are all the same so just take te first \n",
    "theoryids = API.theoryids(**theoryids_dicts[0])\n",
    "theory_plus = theoryids[1].id\n",
    "theory_mid = theoryids[0].id\n",
    "theory_min = theoryids[2].id\n",
    "\n",
    "# Inputs for central theory (used to construct the alphas covmat)\n",
    "inps_centrals = [dict(theoryid=theory_mid, pdf=prior_pdf, **common_dict) for common_dict in common_dicts]\n",
    "\n",
    "# Inputs for plus theory (used to construct the alphas covmat)\n",
    "inps_pluss = [dict(theoryid=theory_plus, pdf=prior_pdf, **common_dict) for common_dict in common_dicts]\n",
    "\n",
    "# Inputs for minus theory prediction (used to construct the alphas covmat)\n",
    "inps_minuss = [dict(theoryid=theory_min, pdf=prior_pdf, **common_dict) for common_dict in common_dicts]\n",
    "\n",
    "# inputs for the computation of the prediction of the fit with cov=C+S, where S is computed using the\n",
    "# inps_central, inps_plus, and inps_minus dictionaries\n",
    "inps_central_fits = [dict(theoryid=theory_mid, pdf={\"from_\": \"fit\"}, **common_dict) for common_dict in common_dicts]\n",
    "\n",
    "prior_theorypreds_centrals = [API.group_result_table_no_table(**inps_central).iloc[:, 2:].mean(axis=1) for inps_central in inps_centrals]\n",
    "\n",
    "prior_theorypreds_pluss = [API.group_result_table_no_table(**inps_plus).iloc[:, 2:].mean(axis=1) for inps_plus in inps_pluss]\n",
    "\n",
    "prior_theorypreds_minuss = [API.group_result_table_no_table(**inps_minus).iloc[:, 2:].mean(axis=1) for inps_minus in inps_minuss]\n",
    "\n",
    "gammas = [prior_theorypreds_plus + prior_theorypreds_minus - 2 * prior_theorypreds_central for prior_theorypreds_plus,prior_theorypreds_minus,prior_theorypreds_central in zip(prior_theorypreds_pluss,prior_theorypreds_minuss,prior_theorypreds_centrals) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0de2658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the values of alphas...\n",
    "alphas_plus = API.theory_info_table(theory_db_id=theory_plus).loc[\"alphas\"].iloc[0]\n",
    "alphas_central = API.theory_info_table(theory_db_id=theory_mid).loc[\"alphas\"].iloc[0]\n",
    "alphas_min = API.theory_info_table(theory_db_id=theory_min).loc[\"alphas\"].iloc[0]\n",
    "\n",
    "# ... and make sure the alphas shift in both directions is symmetric\n",
    "delta_alphas_plus = alphas_plus - alphas_central\n",
    "delta_alphas_min = alphas_central - alphas_min\n",
    "if abs(delta_alphas_min - delta_alphas_plus) > 1e-6:\n",
    "    raise ValueError(\"alphas shifts in both directions is not symmetric\")\n",
    "else:\n",
    "    alphas_step_size = delta_alphas_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0d5e7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_tilde = np.sqrt(covmat_scaling_factor) * (alphas_step_size / np.sqrt(2)) * np.array([1, -1])\n",
    "S_tilde = beta_tilde @ beta_tilde\n",
    "\n",
    "delta_pluss = [(np.sqrt(covmat_scaling_factor) / np.sqrt(2)) * (\n",
    "    prior_theorypreds_plus - prior_theorypreds_central) for prior_theorypreds_plus,prior_theorypreds_central in zip(prior_theorypreds_pluss,prior_theorypreds_centrals) ]\n",
    "\n",
    "delta_minuss = [(np.sqrt(covmat_scaling_factor) / np.sqrt(2)) * (\n",
    "    prior_theorypreds_minus - prior_theorypreds_central\n",
    ") for prior_theorypreds_minus,prior_theorypreds_central in zip(prior_theorypreds_minuss,prior_theorypreds_centrals)]\n",
    "\n",
    "betas = [[delta_plus, delta_minus] for delta_plus, delta_minus in zip(delta_pluss,delta_minuss)]\n",
    "S_hats = [beta_tilde @ beta for beta in betas]\n",
    "\n",
    "Ss = [np.outer(delta_plus, delta_plus) + np.outer(delta_minus, delta_minus) for delta_plus,delta_minus in zip(delta_pluss,delta_minuss)]\n",
    "Ss = [pd.DataFrame(S, index=delta_minus.index, columns=delta_minus.index) for S,delta_minus in zip(Ss, delta_minuss)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ea4ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHAPDF 6.4.0 loading all 496 PDFs in set 240715-ab-multict-fseed10290-tcm-nlo\n",
      "240715-ab-multict-fseed10290-tcm-nlo, version 1; 496 PDF members\n",
      "LHAPDF 6.4.0 loading all 496 PDFs in set 240715-ab-multict-fseed3345348918-tcm-nlo\n",
      "240715-ab-multict-fseed3345348918-tcm-nlo, version 1; 496 PDF members\n"
     ]
    }
   ],
   "source": [
    "theorypreds_fits = [API.group_result_table_no_table(**inps_central_fit).iloc[:, 2:] for inps_central_fit in inps_central_fits]\n",
    "\n",
    "t0theoryid = API.t0theoryid(**theoryids_dicts[0])\n",
    "\n",
    "# Experimental covariance matrix\n",
    "Cs = [API.groups_covmat(\n",
    "    use_t0=True,\n",
    "    datacuts={\"from_\": \"fit\"},\n",
    "    t0pdfset={\"from_\": \"datacuts\"},\n",
    "    theoryid=t0theoryid.id,\n",
    "    faketheoryid=t0theoryid.id,\n",
    "    t0theoryid=t0theoryid.id,\n",
    "    **common_dict\n",
    ")for common_dict in common_dicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e125b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different from the prediction of the mean PDF (i.e. replica0)\n",
    "mean_predictions = [theorypreds_fit.mean(axis=1) for theorypreds_fit in theorypreds_fits ]\n",
    "\n",
    "Xs = [np.zeros_like(C.values) for C in Cs]\n",
    "for theorypreds_fit, X, mean_prediction in zip(theorypreds_fits, Xs, mean_predictions ):\n",
    "    for i in range(theorypreds_fit.shape[1]):\n",
    "        X += np.outer(\n",
    "            (theorypreds_fit.iloc[:, i] - mean_prediction),\n",
    "            (theorypreds_fit.iloc[:, i] - mean_prediction),\n",
    "        )\n",
    "    X *= 1 / theorypreds_fit.shape[1]\n",
    "\n",
    "pseudodatas = [API.read_pdf_pseudodata(**common_dict) for common_dict in common_dicts]\n",
    "dat_repss = [pd.concat(\n",
    "    [i.pseudodata.reindex(prior_theorypreds_central.index) for i in pseudodata], axis=1\n",
    ") for pseudodata,prior_theorypreds_central in zip(pseudodatas,prior_theorypreds_centrals)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d2d4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "invcovs = [np.linalg.inv(C + S) for C,S in zip(Cs, Ss)]\n",
    "delta_T_tildes = [-S_hat @ invcov @ (mean_prediction - dat_reps.mean(axis=1)) for S_hat, invcov, mean_prediction,dat_reps  in zip(S_hats, invcovs, mean_predictions,dat_repss)]\n",
    "P_tildes = [S_hat.T @ invcov @ X @ invcov @ S_hat + S_tilde - S_hat.T @ invcov @ S_hat for S_hat, invcov, X  in zip(S_hats, invcovs,Xs)]\n",
    "preds = [alphas_central + delta_T_tilde for delta_T_tilde in delta_T_tildes]\n",
    "uncs = [np.sqrt(P_tilde) for P_tilde in P_tildes]\n",
    "tcm_alphas_results = []\n",
    "for pred, unc in zip(preds, uncs):\n",
    "    tcm_alphas_results.append([pred, unc])\n",
    "    print(rf\"Prediction for $\\alpha_s$: {pred:.4f} Â± {unc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be75ceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"tcm_alphas_results\", np.array(tcm_alphas_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb29a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(\"tcm_alphas_results.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
